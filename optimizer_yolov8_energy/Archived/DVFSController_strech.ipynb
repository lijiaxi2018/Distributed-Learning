{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(filepath):\n",
    "\twith open(filepath, 'r') as file:\n",
    "\t\tdata = json.load(file)\n",
    "\treturn data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "STANDARD_SIZE = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "EFFICIENCY_TABLE_PATH = '../assets/result/energy/Efficiency-Table-960.json'\n",
    "EFFICIENCY_TABLE = load_json(EFFICIENCY_TABLE_PATH)\n",
    "EFFICIENCY_TABLE_INVERSE = (1. - np.array(EFFICIENCY_TABLE)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_2d_array(arr, new_shape):\n",
    "\t\t\"\"\"\n",
    "\t\tReshape a 2D array to a specific shape, retaining the edge values and \n",
    "\t\tmaintaining the trend for non-edge values.\n",
    "\t\t\n",
    "\t\t:param arr: 2D list of numbers\n",
    "\t\t:param new_shape: tuple of (new_rows, new_cols)\n",
    "\t\t:return: reshaped 2D list\n",
    "\t\t\"\"\"\n",
    "\t\tarr = np.array(arr)\n",
    "\t\torig_rows, orig_cols = arr.shape\n",
    "\t\tnew_rows, new_cols = new_shape\n",
    "\n",
    "\t\t# Step 1: Interpolate rows\n",
    "\t\tintermediate_array = np.zeros((orig_rows, new_cols))\n",
    "\t\tfor i in range(orig_rows):\n",
    "\t\t\t\tintermediate_array[i, :] = np.interp(np.linspace(0, orig_cols-1, new_cols), np.arange(orig_cols), arr[i, :])\n",
    "\n",
    "\t\t# Step 2: Interpolate columns\n",
    "\t\tnew_array = np.zeros((new_rows, new_cols))\n",
    "\t\tfor j in range(new_cols):\n",
    "\t\t\t\tnew_array[:, j] = np.interp(np.linspace(0, orig_rows-1, new_rows), np.arange(orig_rows), intermediate_array[:, j])\n",
    "\n",
    "\t\t# Ensure edge values are exactly as in the original array\n",
    "\t\tnew_array[0, :] = np.interp(np.linspace(0, orig_cols-1, new_cols), np.arange(orig_cols), arr[0, :])\n",
    "\t\tnew_array[-1, :] = np.interp(np.linspace(0, orig_cols-1, new_cols), np.arange(orig_cols), arr[-1, :])\n",
    "\t\tnew_array[:, 0] = np.interp(np.linspace(0, orig_rows-1, new_rows), np.arange(orig_rows), arr[:, 0])\n",
    "\t\tnew_array[:, -1] = np.interp(np.linspace(0, orig_rows-1, new_rows), np.arange(orig_rows), arr[:, -1])\n",
    "\n",
    "\t\treturn new_array.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "STANDARD_EFFICIENCY_TABLE = interpolate_2d_array(EFFICIENCY_TABLE_INVERSE, (STANDARD_SIZE, STANDARD_SIZE))\n",
    "with open(\"../assets/result/optimizer_energy/Standard-Efficiency-Table\" + \".json\", 'w') as file:\n",
    "    json.dump(STANDARD_EFFICIENCY_TABLE, file, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_PATH = '../assets/result/energy/YOLOv8-1800-960.json'\n",
    "ENERGY_RESULT = load_json(RESULT_PATH)\n",
    "ENERGY_SCALE = 10**6\n",
    "NUM_FRAME = 1800\n",
    "RESAMPLING_INTERVAL = 15\n",
    "\n",
    "CPU_FREQ = [\n",
    "\t\t115200, 192000, 268800, 345600, 422400, 499200, 576000, 652800, 729600,\n",
    "\t\t806400, 883200, 960000, 1036800, 1113600, 1190400, 1267200, 1344000,\n",
    "\t\t1420800, 1497600, 1574400, 1651200, 1728000, 1804800, 1881600, 1958400,\n",
    "\t\t2035200, 2112000, 2188800, 2201600\n",
    "]\n",
    "\n",
    "GPU_FREQ = [\n",
    "\t\t306000000, 408000000, 510000000, 612000000, 714000000, 816000000, 918000000,\n",
    "\t\t1020000000, 1122000000, 1224000000, 1300500000\n",
    "]\n",
    "\n",
    "COMBINED_FPS_PATH = \"../assets/result/accuracy/Combined-FPS.json\"\n",
    "REQUIRED_THROUGHPUT = load_json(COMBINED_FPS_PATH)\n",
    "\n",
    "def evaluate_power(cpu_freq, gpu_freq, result_dict=ENERGY_RESULT):\n",
    "\t\tkey = f\"{cpu_freq}:{gpu_freq}\"\n",
    "\t\tenergy = result_dict[key][1] + result_dict[key][2]\n",
    "\t\ttime = result_dict[key][0]\n",
    "\t\tpower = energy / time / ENERGY_SCALE\n",
    "\t\treturn power\n",
    "\n",
    "def evaluate_throughput(cpu_freq, gpu_freq, result_dict=ENERGY_RESULT):\n",
    "\t\tkey = f\"{cpu_freq}:{gpu_freq}\"\n",
    "\t\ttime = result_dict[key][0]\n",
    "\t\tthroughput = NUM_FRAME / time\n",
    "\t\treturn throughput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.exceptions import NotFittedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_efficiency_table = interpolate_2d_array(STANDARD_EFFICIENCY_TABLE, (len(GPU_FREQ), len(CPU_FREQ)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 0.375\n",
    "np.random.seed(42)\n",
    "efficiency_array = np.array(real_efficiency_table)\n",
    "\n",
    "# Data storage for observed points\n",
    "observed_data = {'X': [], 'y': []}\n",
    "\n",
    "# Initialize Gaussian Process Regressor\n",
    "kernel = C(1.0, (1e-3, 1e3)) * RBF(1, (1e-2, 1e2))\n",
    "gpr = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, alpha=1e-2)\n",
    "\n",
    "# Standard Scaler for input normalization\n",
    "scaler = StandardScaler()\n",
    "\n",
    "def update_model(cpu_freq, gpu_freq, real_throughput):\n",
    "\t# Update observed data\n",
    "\tobserved_data['X'].append([cpu_freq, gpu_freq])\n",
    "\tobserved_data['y'].append(real_throughput)\n",
    "\t\n",
    "\t# Fit model if we have at least one observation\n",
    "\tif len(observed_data['X']) > 1:\n",
    "\t\tX = np.array(observed_data['X'])\n",
    "\t\ty = np.array(observed_data['y'])\n",
    "\t\tX_scaled = scaler.fit_transform(X) # Standardization\n",
    "\t\tgpr.fit(X_scaled, y)\n",
    "\n",
    "def suggest_combination(required_throughput):\n",
    "\t# Define the search space\n",
    "\tsearch_space = np.array([[cf, gf] for cf in CPU_FREQ for gf in GPU_FREQ])\n",
    "\n",
    "\t# Predict throughputs using the model\n",
    "\tif len(observed_data['X']) == 0:\n",
    "\t\treturn CPU_FREQ[-1], GPU_FREQ[-1]\n",
    "\telif len(observed_data['X']) == 1:\n",
    "\t\treturn CPU_FREQ[0], GPU_FREQ[0]\n",
    "\telse:\n",
    "\t\tsearch_space_scaled = scaler.transform(search_space) # Standardization\n",
    "\t\tpredicted_throughputs, sigma = gpr.predict(search_space_scaled, return_std=True)\n",
    "\t\n",
    "\t# Filter combinations that meet the required throughput\n",
    "\tvalid_combinations = search_space[predicted_throughputs >= required_throughput]\n",
    "\t\n",
    "\t# If no valid combination, return the most efficient combination\n",
    "\tif len(valid_combinations) == 0:\n",
    "\t\tmax_efficiency_index = np.unravel_index(np.argmax(efficiency_array, axis=None), efficiency_array.shape)\n",
    "\t\treturn CPU_FREQ[max_efficiency_index[1]], GPU_FREQ[max_efficiency_index[0]]\n",
    "\n",
    "\t# Calculate efficiency and distance for each valid combination\n",
    "\tefficiencies = [efficiency_array[GPU_FREQ.index(gf), CPU_FREQ.index(cf)] for cf, gf in valid_combinations]\n",
    "\tdistances = [min((predicted_throughput - required_throughput) / required_throughput, 1) for predicted_throughput in predicted_throughputs[predicted_throughputs >= required_throughput]]\n",
    "\n",
    "\t# Calculate the combined score\n",
    "\tscores = [w * eff + (1 - w) * (1 - dist) for eff, dist in zip(efficiencies, distances)]\n",
    "\tbest_combination_index = np.argmax(scores)\n",
    "\t\n",
    "\tbest_combination = valid_combinations[best_combination_index]\n",
    "\treturn best_combination[0], best_combination[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiaxili/opt/anaconda3/lib/python3.8/site-packages/sklearn/gaussian_process/_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/Users/jiaxili/opt/anaconda3/lib/python3.8/site-packages/sklearn/gaussian_process/_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/Users/jiaxili/opt/anaconda3/lib/python3.8/site-packages/sklearn/gaussian_process/_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/Users/jiaxili/opt/anaconda3/lib/python3.8/site-packages/sklearn/gaussian_process/_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/Users/jiaxili/opt/anaconda3/lib/python3.8/site-packages/sklearn/gaussian_process/_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/Users/jiaxili/opt/anaconda3/lib/python3.8/site-packages/sklearn/gaussian_process/_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/Users/jiaxili/opt/anaconda3/lib/python3.8/site-packages/sklearn/gaussian_process/_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/Users/jiaxili/opt/anaconda3/lib/python3.8/site-packages/sklearn/gaussian_process/_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/Users/jiaxili/opt/anaconda3/lib/python3.8/site-packages/sklearn/gaussian_process/_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    }
   ],
   "source": [
    "# highest_throughput = evaluate_throughput(CPU_FREQ[-1], GPU_FREQ[-1])\n",
    "# lowest_throughput = evaluate_throughput(CPU_FREQ[0], GPU_FREQ[0])\n",
    "# update_model(CPU_FREQ[-1], GPU_FREQ[-1], highest_throughput)\n",
    "# update_model(CPU_FREQ[0], GPU_FREQ[0], lowest_throughput)\n",
    "\n",
    "selected_frequencies = []\n",
    "\n",
    "for i, required_throughput in enumerate(REQUIRED_THROUGHPUT):\n",
    "\tcpu_freq, gpu_freq = suggest_combination(required_throughput)\n",
    "\tselected_frequencies.append((cpu_freq, gpu_freq))\n",
    "\treal_throughput = evaluate_throughput(cpu_freq, gpu_freq)\n",
    "\tupdate_model(cpu_freq, gpu_freq, real_throughput)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Power Overuse Rate: 0.02814101964359242\n",
      "Average Throughput Surplus Rate: 0.039693562610229285\n",
      "Average Throughput Shortage Rate: 0.10857422147744727\n"
     ]
    }
   ],
   "source": [
    "OPTIMIZER_ENERGY_RESULT = selected_frequencies\n",
    "EFFICIENT_POWER_RESULT_PATH = '../assets/result/energy/Dict-Per-Real-Second-960.json'\n",
    "EFFICIENT_POWER_RESULT = load_json(EFFICIENT_POWER_RESULT_PATH)\n",
    "\n",
    "power_overuse_rate_list = []\n",
    "output_throughput_list = []\n",
    "output_throughput_surplus_list = []\n",
    "output_throughput_shortage_list = []\n",
    "for i, freq_tuple in enumerate(OPTIMIZER_ENERGY_RESULT):\n",
    "\tkey = f\"{freq_tuple[0]}:{freq_tuple[1]}\"\n",
    "\toutput_time = ENERGY_RESULT[key][0]\n",
    "\toutput_throughput = round(NUM_FRAME / output_time)\n",
    "\toutput_power = (ENERGY_RESULT[key][1] + ENERGY_RESULT[key][2]) / output_time / ENERGY_SCALE\n",
    "\n",
    "\tefficient_data = EFFICIENT_POWER_RESULT[str(output_throughput)][1]\n",
    "\tefficient_time = efficient_data[0]\n",
    "\tefficient_power = (efficient_data[1] + efficient_data[2]) / efficient_time / ENERGY_SCALE\n",
    "\n",
    "\ttarget_throughput = REQUIRED_THROUGHPUT[i]\n",
    "\toutput_throughput_surplus_list.append(max((output_throughput - target_throughput), 0) / (0.5 * (output_throughput + target_throughput)))\n",
    "\toutput_throughput_shortage_list.append(max((target_throughput - output_throughput), 0) / (0.5 * (output_throughput + target_throughput)))\n",
    "\t\n",
    "\toutput_throughput_list.append(output_throughput)\n",
    "\tpower_overuse_rate_list.append( (output_power - efficient_power) / (0.5 * (output_power + efficient_power)) )\n",
    "\n",
    "time = list(np.array(range(len(REQUIRED_THROUGHPUT))) * RESAMPLING_INTERVAL * 1.)\n",
    "\n",
    "print(f\"Average Power Overuse Rate: {np.average(np.array(power_overuse_rate_list))}\")\n",
    "print(f\"Average Throughput Surplus Rate: {np.average(np.array(output_throughput_surplus_list))}\")\n",
    "print(f\"Average Throughput Shortage Rate: {np.average(np.array(output_throughput_shortage_list))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_frequencies = [(int(x), int(y)) for x, y in selected_frequencies]\n",
    "with open(\"../assets/result/optimizer_energy/Real-Frequency\" + \".json\", 'w') as file:\n",
    "\t\tjson.dump(selected_frequencies, file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
